from ._genomic_signal import *
from .persistence import *
from .array_helpers import *
import os
import gffutils
import pybedtools
from pybedtools.featurefuncs import TSS
from gffutils.helpers import asinterval
import multiprocessing
import numpy as np
import sys
from matplotlib import pyplot as plt
import subprocess
from .plotutils import *

def tss_generator(db):
    """
    Generator function to yield TSS of each annotated transcript
    """
    for transcript in db.features_of_type('transcript'):
        yield TSS(asinterval(transcript), upstream=1, downstream=0)

def generate_arrays_features_from_tsses_from_db(dbPath, ipSignalPath, extensionIp,inputSignalPath,extensionInput, genome):

    """
    Function to process ChIP-seq data, specifically to analyze the protein enrichment signal in certain genomic regions, such as transcription start sites (TSS)

    Params:
        - dbPath: String: The path where database of CHIP-seq data is stored (It must be a db generated by the CHIP-seq data with pybedtools library)
        - ipSignalPath: String: The path where IP signal data is stored
        - extensionIp: String: Type of the file of the IP signal data file. Example:('bigwig','bam','bed',...)
        - inputSignalPath: String: The path where INPUT signal data is stored
        - extensionInput: String: Type of the file of the INPUT signal data file example:('bigwig','bam','bed',...)
        - genome: String: The genome of the CHIP-seq data we want to analyze. Example: ('hg19','hg38',...)
    """

    ##Primer paso
    db = gffutils.FeatureDB(dbPath) #Primer paso
    tsses = pybedtools.BedTool(tss_generator(db)).saveas('tsses.gtf')

    remove_duplicates("tsses.gtf")
    tsses = pybedtools.BedTool("tsses.gtf")
    tsses_1kb = tsses.slop(b=1000, genome=genome, output='tsses-1kb.gtf')

    subprocess.run(["bash", "solochr16.3.sh"])
    subprocess.run(["bash", "solochr16.4.sh"])



    ##Segundo paso
    ip_signal = genomic_signal(ipSignalPath,extensionIp)
    input_signal = genomic_signal(inputSignalPath,extensionInput)




    print(ip_signal,input_signal)
    processes = multiprocessing.cpu_count()
    if not os.path.exists('example.npz'):

        ##Tercer paso

        # The signal is the IP ChIP-seq BAM file.
        ip_array = ip_signal.array(

            # Look at signal over these windows
            tsses_1kb,

            # Bin signal into this many bins per window
            bins=100,

            # Use multiple CPUs. Dramatically speeds up run time.
            processes=processes)

        # print(ip_array[0][:10])
        # Do the same thing for input.

        ##Cuartopaso
        input_array = input_signal.array(
            tsses_1kb,
            bins=100,
            processes=processes)

        # print(input_array[:10])



        # Normalize to library size. The values in the array
        # will be in units of "reads per million mapped reads"
        ##SExto paso
        # print(ip_array)

        for i in ip_array:
            i[0]['values'] /= ip_signal.mapped_read_count() / 1e6

        for y in input_array:
            y[0]['values'] /= input_signal.mapped_read_count() / 1e6
        # ip_array /= ip_signal.mapped_read_count() / 1e6
        # input_array /= input_signal.mapped_read_count() / 1e6


        # print("Ip_array: " , ip_array)
        # print("Input_array: " , input_array)

        ##SExto paso
        # Cache to disk. The data will be saved as "example.npz" and "example.features".
        save_features_and_arrays(
            features=tsses,
            arrays={'ip': ip_array, 'input': input_array},
            prefix='example',
            link_features=True,
            overwrite=True)



    features, arrays = load_features_and_arrays(prefix='example')
    return features ,arrays ,tsses, tsses_1kb

def values_array(array_ip, array_input):
    arrays_ip = []
    arrays_input = []
    for x in array_ip:
       arrays_ip.append( x[0]['values'])
    for y in array_input:
       arrays_input.append( y[0]['values'])
    # print(arrays_ip)
    arrays_ip = np.array(arrays_ip)
    arrays_input = np.array(arrays_input)

    return arrays_ip, arrays_input


def calculate_peaks_with_gene_name(arrays_ip, arrays_input):
    normalized_subtracted = np.array([])
    try_boolean = []
    for index,x in enumerate(arrays_ip):
        # print(index)
        # print(arrays_ip)
        normalized_subtracted = np.append(normalized_subtracted,{ 'values': arrays_ip[index][0]['values']-arrays_input[index][0]['values'],
                                                                  'gene_name': arrays_ip[index][0]['gene_name'],
                                                                  'chr': arrays_ip[index][0]['chr'],
                                                                  'start': arrays_ip[index][0]['start'],
                                                                  'end': arrays_ip[index][0]['end'],
                                                                  'strand': arrays_ip[index][0]['strand']})


    return normalized_subtracted


def calculate_peaks(arrays_ip, arrays_input):

    """
    Function to calculate the peaks between the IP signal and INPUT signal.
    Params:
        - arrays_ip: Array: The array of the IP signal data
        - arrays_input: Array: The array of the INPUT signal data
    """

    if(len(arrays_ip) != len(arrays_input)):
        sys.stderr.write("Length of ip is different from input array")
    peaks = arrays_ip - arrays_input
    return peaks


def distance_from_tss_chipSeq(arrays_ip, arrays_input, name=""):

    """
    Function to show in a graphic the distance of IP signal data and INPUT signal data from the TSS.
    Params:
        - arrays_ip: Array: The array of the IP signal data
        - arrays_input: Array: The array of the INPUT signal data
    """

    x = np.linspace(-1000, 1000, 100)


    # Create a figure and axes
    fig = plt.figure()
    ax = fig.add_subplot(111)


    # Plot the IP:
    ax.plot(
        # use the x-axis values we created
        x,

        # axis=0 takes the column-wise mean, so with
        # 100 columns we'll have 100 means to plot
        arrays_ip.mean(axis=0),

        # Make it red
        color='r',

        # Label to show up in legend
        label='IP')


    # Do the same thing with the input
    ax.plot(
        x,
        arrays_input.mean(axis=0),
        color='k',
        label='input')


    # Add a vertical line at the TSS, at position 0
    ax.axvline(0, linestyle=':', color='k')


    # Add labels and legend
    ax.set_xlabel('Distance from TSS (bp)')
    ax.set_ylabel('Average read coverage (per million mapped reads)')
    ax.legend(loc='best')
    ax.set_title(name)
    return fig


##Hacer que homer lo instale el propio usuario
def create_homer_tag_directory(name,file):
    subprocess.run(["makeTagDirectory",name,file])
    return


def homer_peaks(tag_directory,style="factor",output="auto"):
    print(output,style)

    subprocess.run(["findPeaks", tag_directory, "-style",style,"-o",output])
    return

def homer_annotate_peaks(file_directory,gene, output):

    with open(output, "w") as out_file, open("logs.log", "w") as err_file:
        subprocess.run(["annotatePeaks.pl", file_directory, gene], stdout=out_file, stderr=err_file)



def genes_not_used_with_rna(tsses, data, normalized_subtracted):

    """
    Function to delete the genes not used in both data (chip and rna). Need to use this function to analyse both them together because
    having more genes can have problems with array length. Important to be in the same order normalized_subtracted and tsses because
    index are used

    Params:
        -tsses: Pybedtool class where there is chip-seq data
        -data: DEseq2ResultsPrueba class where there is rna-seq data
        -normalized_subtracted: Array where have the chip-seq peaks calculated
    """
    df2 = tsses.to_dataframe()
    print(df2)
    gene_used = []
    gene_not_used_chip = []
    indexs = []
    values_not_data = []
    for idx,value in enumerate(df2.values):
        if value[8].split(";")[3].split(" ")[2].split('"')[1] in data.index:
            indexs.append(idx)
            gene_used.append(value[8].split(";")[3].split(" ")[2].split('"')[1])
        else:
            gene_not_used_chip.append(value[8].split(";")[3].split(" ")[2].split('"')[1])


    with open("genes_not_used_chip_seq.log", "w") as chip_log:
        for gene in gene_not_used_chip:
            chip_log.write(f"{gene}\n")

    for value_data in data.index:
        if value_data not in gene_used:
            values_not_data.append(value_data)

    with open("genes_not_used_rna_seq.log", "w") as rna_log:
        for gene in values_not_data:
            rna_log.write(f"{gene}\n")

    print("\nGenes_not_used_rna-seq: ",values_not_data)
    normalized_subtracted_good= []
    ##For put good normalized subtracted
    for i in range(len(normalized_subtracted)):
        if i in indexs:
            normalized_subtracted_good.append(normalized_subtracted[i])
    ##FOr deseq2
    data = data.drop(values_not_data)

    normalized_subtracted= np.array(normalized_subtracted_good)
    print("Normalized subtract len: ", len(normalized_subtracted))

    return normalized_subtracted,data

    # data2['log2FoldChange'] = data["fpkm"]
    # print("Len data2: ",len(data2), "DAta2: ",data2)
    # print("\n\nlen data: ",len(data), "Data: ", data)

def bigwigToBed(bwFile, bedNameFile):
    bwFile = pyBigWig.open(bwFile)
    chroms = bwFile.chroms()

    bed_data = []
    i = 0

    for chrom in chroms:
        intervals = bwFile.intervals(chrom)
        for start, end, value  in intervals:
            bed_data.append([chrom, start, end, i, value, ""])
            i += 1

    bed_df = pd.DataFrame(bed_data, columns=["chrom", "start", "end", "ID", "value", ""])
    bed_df.to_csv(bedNameFile, sep='\t', header=True, index=False)

def array_gene_name_and_annotation(bedFile_ip, bedFile_input,gene, arrays_ip, arrays_input):

    print(len(arrays_ip), len(arrays_input))

    df_ip = pd.read_csv((bedFile_ip+".txt"), delimiter="\t")
    df_input = pd.read_csv((bedFile_input+".txt"), delimiter="\t")
    df_ip["Annotation"] = df_ip["Annotation"].str.replace(r'\(.*', '', regex=True)
    unique_values_ip = df_ip['Annotation'].unique()
    df_input["Annotation"] = df_input["Annotation"].str.replace(r'\(.*', '', regex=True)
    unique_values_input = df_input['Annotation'].unique()

    print("input",unique_values_input, "IP",unique_values_ip)

    array_gene_annotation_ip = []
    array_gene_annotation_input = []
    for idx, row in df_ip.iterrows():
        array_gene_annotation_ip.append({"gene_name": row['Gene Name'], "annotation": row['Annotation']})
    for idx, row in df_input.iterrows():
        array_gene_annotation_input.append({"gene_name": row['Gene Name'], "annotation": row['Annotation']})


    df_ip = {key:[] for key in unique_values_ip}
    df_input = {key:[] for key in unique_values_input}

    for x in arrays_ip:
        for y in array_gene_annotation_ip:
            if x[0]['gene_name'] == y['gene_name']:
                df_ip[y['annotation']].append(x[0]['values'])
                break

    for i in arrays_input:
        for j in array_gene_annotation_input:
            if i[0]['gene_name'] == j['gene_name']:
                df_input[j['annotation']].append(i[0]['values'])
                break
    # print(df_input, df_ip)

    for key in df_ip:
        df_ip[key] = np.array(df_ip[key])
    for key in df_input:
        df_input[key] = np.array(df_input[key])

    print("Cantidad de vecees de elementos IP: \n", len(df_ip["exon"]))
    print("\nCantidad de vecees de elementos INPUT:\n ", len(df_input["exon"]))

    for key in df_ip:
        if len(df_ip[key]) == 0 or len(df_input[key]) == 0:
            continue
        else:
            fig = distance_from_tss_chipSeq(arrays_ip=df_ip[key], arrays_input=df_input[key], name=key)

    plt.show()

    df_normalized_subtracted = {}

    for key in df_ip:
        if len(df_ip[key]) == 0 or len(df_input[key]) == 0:
            continue
        else:
            print(len(df_ip[key]),len(df_input[key]) , df_input[key])
            df_normalized_subtracted[key] = calculate_peaks(df_ip[key] , df_input[key])

    print (df_normalized_subtracted)


    for key in df_normalized_subtracted:

        fig = imshow(
        df_normalized_subtracted[key],
        x=x,
        figsize=(3, 7),
        percentile=True,
        vmin=5,
        vmax=99,
        line_kwargs=dict(color='k', label='All'),
        fill_kwargs=dict(color='k', alpha=0.3),
        )



        fig = imshow(
            df_normalized_subtracted[key],
            x=x,
            figsize=(3, 7),
            vmin=5, vmax=99,  percentile=True,
            line_kwargs=dict(color='k', label='All'),
            fill_kwargs=dict(color='k', alpha=0.3),
            sort_by=df_normalized_subtracted[key].mean(axis=1)
        )

        fig = imshow(
            df_normalized_subtracted[key],
            x=x,
            figsize=(3, 7),
            vmin=5, vmax=99,  percentile=True,
            line_kwargs=dict(color='k', label='All'),
            fill_kwargs=dict(color='k', alpha=0.3),
            sort_by=np.argmax(df_normalized_subtracted[key], axis=1)
        )



        fig = imshow(
            df_normalized_subtracted[key],
            x=x,
            figsize=(3, 7),
            vmin=5, vmax=99,  percentile=True,
            line_kwargs=dict(color='k', label='All'),
            fill_kwargs=dict(color='k', alpha=0.3),
            sort_by=df_normalized_subtracted[key].mean(axis=1)
        )

        print("AHora viene: ", key)

        plt.show()



def array_gene_name_and_annotation_2(normalized_subtracted):
    bed_data = []
    i = 0
    for e in normalized_subtracted:
        i +=1
        bed_data.append([e['chr'], e['start'], e['end'], i ])
    
    df_bed = pd.DataFrame(bed_data, columns=['chr', 'start', 'end', 'ID'])
    df_bed.to_csv("normalized_subtracted.bed",sep='\t', header=True, index=False)
    homer_annotate_peaks(file_directory="normalized_subtracted.bed",gene="mm10", output="normalized_subtracted.bed.txt")
    df_homer = pd.read_csv("normalized_subtracted.bed.txt",delimiter="\t")
    print(df_homer)
    df_homer["Annotation"] = df_homer["Annotation"].str.replace(r'\(.*', '', regex=True)
    print(df_homer)
    unique_values_homer = df_homer["Annotation"].unique()
    array_gene_annotation = []
    for idx, row in df_homer.iterrows():
        print(row['Annotation'])
        array_gene_annotation.append({"gene_name": row['Gene Name'], "annotation": row['Annotation']})

    df_homer_total = {key:[] for key in unique_values_homer}

    for x in normalized_subtracted:
        for y in array_gene_annotation:
            if x['gene_name'] == y['gene_name']:
                df_homer_total[y['annotation']].append(x['values'])
                break
    x = np.linspace(-1000, 1000, 100)
    for key in df_homer_total:

        if len(df_homer_total[key]) == 0:
            continue
        
        else:
            df_homer_total[key] = np.array(df_homer_total[key])

            fig = imshow(
            df_homer_total[key],
            x=x,
            figsize=(3, 7),
            percentile=True,
            vmin=5,
            vmax=99,
            line_kwargs=dict(color='k', label='All'),
            fill_kwargs=dict(color='k', alpha=0.3),
            )



            fig = imshow(
                df_homer_total[key],
                x=x,
                figsize=(3, 7),
                vmin=5, vmax=99,  percentile=True,
                line_kwargs=dict(color='k', label='All'),
                fill_kwargs=dict(color='k', alpha=0.3),
                sort_by=df_homer_total[key].mean(axis=1)
            )

            fig = imshow(
                df_homer_total[key],
                x=x,
                figsize=(3, 7),
                vmin=5, vmax=99,  percentile=True,
                line_kwargs=dict(color='k', label='All'),
                fill_kwargs=dict(color='k', alpha=0.3),
                sort_by=np.argmax(df_homer_total[key], axis=1)
            )



            fig = imshow(
                df_homer_total[key],
                x=x,
                figsize=(3, 7),
                vmin=5, vmax=99,  percentile=True,
                line_kwargs=dict(color='k', label='All'),
                fill_kwargs=dict(color='k', alpha=0.3),
                sort_by=df_homer_total[key].mean(axis=1)
            )

            print("AHora viene: ", key)

            plt.show()
            


    print(normalized_subtracted,df_homer_total)

    








