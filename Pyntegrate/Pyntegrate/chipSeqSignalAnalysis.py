from ._genomic_signal import *
from .persistence import *
from .array_helpers import *
import os
import gffutils
import pybedtools
from pybedtools.featurefuncs import TSS
from gffutils.helpers import asinterval
import multiprocessing
import numpy as np
import sys
from matplotlib import pyplot as plt
import subprocess
from .plotutils import *

def tss_generator(db):
    """
    Generator function to yield TSS of each annotated transcript
    """
    for transcript in db.features_of_type('transcript'):
        yield TSS(asinterval(transcript), upstream=1, downstream=0)

def generate_arrays_features_from_tsses_from_db(dbPath, ipSignalPath, extensionIp,inputSignalPath,extensionInput, genome, bins):

    """
    Function to process ChIP-seq data, specifically to analyze the protein enrichment signal in certain genomic regions, such as transcription start sites (TSS)

    Params:
        - dbPath: String: The path where database of CHIP-seq data is stored (It must be a db generated by the CHIP-seq data with pybedtools library)
        - ipSignalPath: String: The path where IP signal data is stored
        - extensionIp: String: Type of the file of the IP signal data file. Example:('bigwig','bam','bed',...)
        - inputSignalPath: String: The path where INPUT signal data is stored
        - extensionInput: String: Type of the file of the INPUT signal data file example:('bigwig','bam','bed',...)
        - genome: String: The genome of the CHIP-seq data we want to analyze. Example: ('hg19','hg38',...)
    """

    db = gffutils.FeatureDB(dbPath)
    tsses = pybedtools.BedTool(tss_generator(db)).saveas('tsses.gtf')

    remove_duplicates("tsses.gtf")
    tsses = pybedtools.BedTool("tsses.gtf")
    tsses_1kb = tsses.slop(b=1000, genome=genome, output='tsses-1kb.gtf')

    ip_signal = genomic_signal(ipSignalPath,extensionIp)
    input_signal = genomic_signal(inputSignalPath,extensionInput)




    print(ip_signal,input_signal)
    processes = multiprocessing.cpu_count()
    if not os.path.exists('example.npz'):

        ip_array = ip_signal.array(
            tsses_1kb,
            bins=bins,
            processes=processes)
        input_array = input_signal.array(
            tsses_1kb,
            bins=bins,
            processes=processes)

        for i in ip_array:
            i[0]['values'] /= ip_signal.mapped_read_count() / 1e6

        for y in input_array:
            y[0]['values'] /= input_signal.mapped_read_count() / 1e6
        save_features_and_arrays(
            features=tsses,
            arrays={'ip': ip_array, 'input': input_array},
            prefix='example',
            link_features=True,
            overwrite=True)
        
    features, arrays = load_features_and_arrays(prefix='example')
    return features ,arrays ,tsses, tsses_1kb


def value_array_simple(array):
    """
    This function convert a simple array of object with values and gene info into an array of only values.
    THis works when an open file with IP or INPUT data is open, we can arrify it with the array function of
    the object and it returns an array of object with the values an gene information. So this funcion helps 
    to just have an array of values.

    Params:
        - array: Array get by the array function of BaseSignal object
    """
    array_final = []
    for x in array:
       array_final.append( x[0]['values'])
    array_final = np.array(array_final)

    return array_final

def values_array(array_ip, array_input):

    """
    This function makes the same as the one before but with two arrays because normally it is used to IP and INPUT

    Params:    
        - arrays_ip: IP array get by the array function of the BaseSignal object
        - arrays_input: INPUT array get by array function of the BaseSignal object
    """
    arrays_ip = []
    arrays_input = []
    for x in array_ip:
       arrays_ip.append( x[0]['values'])
    for y in array_input:
       arrays_input.append( y[0]['values'])

    arrays_ip = np.array(arrays_ip)
    arrays_input = np.array(arrays_input)

    return arrays_ip, arrays_input


def calculate_peaks_with_gene_name(arrays_ip, arrays_input):
    normalized_subtracted = np.array([])
    try_boolean = []
    for index,x in enumerate(arrays_ip):

        normalized_subtracted = np.append(normalized_subtracted,{ 'values': arrays_ip[index][0]['values']-arrays_input[index][0]['values'],
                                                                  'gene_name': arrays_ip[index][0]['gene_name'],
                                                                  'chr': arrays_ip[index][0]['chr'],
                                                                  'start': arrays_ip[index][0]['start'],
                                                                  'end': arrays_ip[index][0]['end'],
                                                                  'strand': arrays_ip[index][0]['strand']})


    return normalized_subtracted


def calculate_peaks(arrays_ip, arrays_input):

    """
    Function to calculate the peaks between the IP signal and INPUT signal.
    Params:
        - arrays_ip: Array: The array of the IP signal data
        - arrays_input: Array: The array of the INPUT signal data
    """

    if(len(arrays_ip) != len(arrays_input)):
        sys.stderr.write("Length of ip is different from input array")
    peaks = arrays_ip - arrays_input
    return peaks


def distance_from_tss_chipSeq(arrays_ip, arrays_input, name=""):

    """
    Function to show in a graphic the distance of IP signal data and INPUT signal data from the TSS.
    Params:
        - arrays_ip: Array: The array of the IP signal data
        - arrays_input: Array: The array of the INPUT signal data
    """

    x = np.linspace(-1000, 1000, 100)
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.plot(
        x,
        arrays_ip.mean(axis=0),
        color='r',
        label='IP')

    ax.plot(
        x,
        arrays_input.mean(axis=0),
        color='k',
        label='input')

    ax.axvline(0, linestyle=':', color='k')

    ax.set_xlabel('Distance from TSS (bp)')
    ax.set_ylabel('Average read coverage (per million mapped reads)')
    ax.legend(loc='best')
    ax.set_title(name)
    return fig


##Hacer que homer lo instale el propio usuario
def create_homer_tag_directory(name,file):
    subprocess.run(["makeTagDirectory",name,file])
    return


def homer_peaks(tag_directory,style="factor",output="auto"):
    print(output,style)

    subprocess.run(["findPeaks", tag_directory, "-style",style,"-o",output])
    return

def homer_annotate_peaks(file_directory,gene, output):

    with open(output, "w") as out_file, open("logs.log", "w") as err_file:
        subprocess.run(["annotatePeaks.pl", file_directory, gene], stdout=out_file, stderr=err_file)



def genes_not_used_with_rna(tsses, data, normalized_subtracted, id="gene_name", findBy="gene_name"):

    """
    Function to delete the genes not used in both data (chip and rna). Need to use this function to analyse both them together because
    having more genes can have problems with array length. Important to be in the same order normalized_subtracted and tsses because
    index are used

    Params:
        -tsses: Pybedtool class with the transcriptions
        -data: DEseq2ResultsPrueba class where there is rna-seq data
        -normalized_subtracted: Array where have the chip-seq peaks calculated
        -id: String that indicates the condition filter (gene_name, gene_id,...)
    """
    df2 = tsses.to_dataframe()
    print(df2)
    gene_used = []
    gene_not_used_chip = []
    indexs = []
    values_not_data = []
    miidx = -1
    for idx,value in enumerate(df2.values):
        ##Hacer din√°mico
        # if miidx != -1:
        #     continue
        # else:
        #     for idx, x in enumerate(value[8].split(";")):
        #         if findBy in x:
        #             miidx = idx 
        #             break

        # if value[8].split(";")[miidx].split(" ")[1].split('"')[0] in data[id]:
        #     indexs.append(idx)
        #     gene_used.append(value[8].split(";")[miidx].split(" ")[1].split('"')[0])
        # else:
        #     gene_not_used_chip.append(value[8].split(";")[miidx].split(" ")[1].split('"')[0])
            
        if value[8].split(";")[3].split(" ")[2].split('"')[1] in data[id]:
            indexs.append(idx)
            gene_used.append(value[8].split(";")[3].split(" ")[2].split('"')[1])
        else:
            gene_not_used_chip.append(value[8].split(";")[3].split(" ")[2].split('"')[1])


    with open("genes_not_used_chip_seq.log", "w") as chip_log:
        for gene in gene_not_used_chip:
            chip_log.write(f"{gene}\n")

    for value_data in data.index:
        if value_data not in gene_used:
            values_not_data.append(value_data)

    with open("genes_not_used_rna_seq.log", "w") as rna_log:
        for gene in values_not_data:
            rna_log.write(f"{gene}\n")

    print("\nGenes_not_used_rna-seq: ",values_not_data)
    normalized_subtracted_good= []
    for i in range(len(normalized_subtracted)):
        if i in indexs:
            normalized_subtracted_good.append(normalized_subtracted[i])
    data = data.drop(values_not_data)

    normalized_subtracted= np.array(normalized_subtracted_good)
    print("Normalized subtract len: ", len(normalized_subtracted))

    return normalized_subtracted,data

def genes_not_used_with_rna_with_gene_names( data, normalized_subtracted, id="gene_name", findBy="gene_name"):

    """
    Function to delete the genes not used in both data (chip and rna). Need to use this function to analyse both them together because
    having more genes can have problems with array length. Important to be in the same order normalized_subtracted and tsses because
    index are used

    Params:
        -data: DEseq2ResultsPrueba class where there is rna-seq data
        -normalized_subtracted: Array where have the chip-seq peaks calculated and with names/ids
        -id: String that indicates the condition filter (gene_name, gene_id,...)
    """
    gene_used = []
    gene_not_used_chip = []
    values_not_data = []
    indexs = []
    print(normalized_subtracted)
    for idx, x in enumerate(normalized_subtracted):
        # print(x[id], data[id])
        ##No se si esta comprobaci√≥n se deber√≠a de hacer
        
        if("." in x[id]):
            print(x[id])
            r = x[id].split(".")[0]
        if r in data[id]:
            gene_used.append(r)
            indexs.append(idx)
        else:
            gene_not_used_chip.append(r)

    print(len(normalized_subtracted))


    with open("genes_not_used_chip_seq.log", "w") as chip_log:
        for gene in gene_not_used_chip:
            chip_log.write(f"{gene}\n")

    for value_data in data[id]:
        if value_data not in gene_used:
            values_not_data.append(value_data)

    with open("genes_not_used_rna_seq.log", "w") as rna_log:
        for gene in values_not_data:
            rna_log.write(f"{gene}\n")

    # print("\nGenes_not_used_rna-seq: ",values_not_data)
    normalized_subtracted_good= []
    for i in range(len(normalized_subtracted)):
        if i in indexs:
            normalized_subtracted_good.append(normalized_subtracted[i])
    data = data.drop(values_not_data)

    normalized_subtracted= np.array(normalized_subtracted_good)
    print("Normalized subtract len: ", len(normalized_subtracted))

    return normalized_subtracted,data

def bigwigToBed(bwFile, bedNameFile):

    """
    Function that converts a BigWig file intro a BEd file. 
    Params:
        -bwFile: String: Path to the BigWig file
        -bedNameFile: String: Name to use in the Bed file created
    """
    bwFile = pyBigWig.open(bwFile)
    chroms = bwFile.chroms()

    bed_data = []
    i = 0
    for chrom in chroms:
        intervals = bwFile.intervals(chrom)
        for start, end, score  in intervals:
            bed_data.append([chrom, start, end, i, score, ""])
            i += 1

    bed_df = pd.DataFrame(bed_data, columns=["chrom", "start", "end", "ID", "value", ""])
    bed_df.to_csv(bedNameFile, sep='\t', header=True, index=False)

# def array_gene_name_and_annotation(bedFile_ip, bedFile_input,gene, arrays_ip, arrays_input):

#     print(len(arrays_ip), len(arrays_input))

#     df_ip = pd.read_csv((bedFile_ip+".txt"), delimiter="\t")
#     df_input = pd.read_csv((bedFile_input+".txt"), delimiter="\t")
#     df_ip["Annotation"] = df_ip["Annotation"].str.replace(r'\(.*', '', regex=True)
#     unique_values_ip = df_ip['Annotation'].unique()
#     df_input["Annotation"] = df_input["Annotation"].str.replace(r'\(.*', '', regex=True)
#     unique_values_input = df_input['Annotation'].unique()

#     print("input",unique_values_input, "IP",unique_values_ip)

#     array_gene_annotation_ip = []
#     array_gene_annotation_input = []
#     for idx, row in df_ip.iterrows():
#         array_gene_annotation_ip.append({"gene_name": row['Gene Name'], "annotation": row['Annotation']})
#     for idx, row in df_input.iterrows():
#         array_gene_annotation_input.append({"gene_name": row['Gene Name'], "annotation": row['Annotation']})


#     df_ip = {key:[] for key in unique_values_ip}
#     df_input = {key:[] for key in unique_values_input}

#     for x in arrays_ip:
#         for y in array_gene_annotation_ip:
#             if x[0]['gene_name'] == y['gene_name']:
#                 df_ip[y['annotation']].append(x[0]['values'])
#                 break

#     for i in arrays_input:
#         for j in array_gene_annotation_input:
#             if i[0]['gene_name'] == j['gene_name']:
#                 df_input[j['annotation']].append(i[0]['values'])
#                 break
#     # print(df_input, df_ip)

#     for key in df_ip:
#         df_ip[key] = np.array(df_ip[key])
#     for key in df_input:
#         df_input[key] = np.array(df_input[key])

#     print("Cantidad de vecees de elementos IP: \n", len(df_ip["exon"]))
#     print("\nCantidad de vecees de elementos INPUT:\n ", len(df_input["exon"]))

#     for key in df_ip:
#         if len(df_ip[key]) == 0 or len(df_input[key]) == 0:
#             continue
#         else:
#             fig = distance_from_tss_chipSeq(arrays_ip=df_ip[key], arrays_input=df_input[key], name=key)

#     plt.show()

#     df_normalized_subtracted = {}

#     for key in df_ip:
#         if len(df_ip[key]) == 0 or len(df_input[key]) == 0:
#             continue
#         else:
#             print(len(df_ip[key]),len(df_input[key]) , df_input[key])
#             df_normalized_subtracted[key] = calculate_peaks(df_ip[key] , df_input[key])

#     print (df_normalized_subtracted)


#     for key in df_normalized_subtracted:

#         fig = imshow(
#         df_normalized_subtracted[key],
#         x=x,
#         figsize=(3, 7),
#         percentile=True,
#         vmin=5,
#         vmax=99,
#         line_kwargs=dict(color='k', label='All'),
#         fill_kwargs=dict(color='k', alpha=0.3),
#         )



#         fig = imshow(
#             df_normalized_subtracted[key],
#             x=x,
#             figsize=(3, 7),
#             vmin=5, vmax=99,  percentile=True,
#             line_kwargs=dict(color='k', label='All'),
#             fill_kwargs=dict(color='k', alpha=0.3),
#             sort_by=df_normalized_subtracted[key].mean(axis=1)
#         )

#         fig = imshow(
#             df_normalized_subtracted[key],
#             x=x,
#             figsize=(3, 7),
#             vmin=5, vmax=99,  percentile=True,
#             line_kwargs=dict(color='k', label='All'),
#             fill_kwargs=dict(color='k', alpha=0.3),
#             sort_by=np.argmax(df_normalized_subtracted[key], axis=1)
#         )



#         fig = imshow(
#             df_normalized_subtracted[key],
#             x=x,
#             figsize=(3, 7),
#             vmin=5, vmax=99,  percentile=True,
#             line_kwargs=dict(color='k', label='All'),
#             fill_kwargs=dict(color='k', alpha=0.3),
#             sort_by=df_normalized_subtracted[key].mean(axis=1)
#         )

#         print("AHora viene: ", key)

#         plt.show()

def array_gene_name_and_annotation(normalized_subtracted,bins):
    bed_data = []
    i = 0
    for e in normalized_subtracted:
        i +=1
        bed_data.append([e['chr'], e['start'], e['end'], i ])
    
    df_bed = pd.DataFrame(bed_data, columns=['chr', 'start', 'end', 'ID'])
    df_bed.to_csv("normalized_subtracted.bed",sep='\t', header=True, index=False)

    homer_annotate_peaks(file_directory="normalized_subtracted.bed",gene="mm10", output="normalized_subtracted.bed.txt")
    df_homer = pd.read_csv("normalized_subtracted.bed.txt",delimiter="\t")

    print(df_homer)
    df_homer["Annotation"] = df_homer["Annotation"].str.replace(r'\(.*', '', regex=True)
    print(df_homer)
    unique_values_homer = df_homer["Annotation"].unique()

    array_gene_annotation = []
    for idx, row in df_homer.iterrows():
        array_gene_annotation.append({"gene_name": row['Gene Name'], "annotation": row['Annotation']})

    df_homer_total = {key:[] for key in unique_values_homer}

    for x in normalized_subtracted:
        for y in array_gene_annotation:
            if x['gene_name'] == y['gene_name']:
                df_homer_total[y['annotation']].append(x['values'])
                break
    x = np.linspace(-1000, 1000, bins)

    
    for key in df_homer_total:

        if len(df_homer_total[key]) == 0:
            continue
        
        else:
            df_homer_total[key] = np.array(df_homer_total[key])

            fig = imshow(
            df_homer_total[key],
            x=x,
            figsize=(3, 7),
            percentile=True,
            vmin=5,
            vmax=99,
            line_kwargs=dict(color='k', label='All'),
            fill_kwargs=dict(color='k', alpha=0.3),
            )



            fig = imshow(
                df_homer_total[key],
                x=x,
                figsize=(3, 7),
                vmin=5, vmax=99,  percentile=True,
                line_kwargs=dict(color='k', label='All'),
                fill_kwargs=dict(color='k', alpha=0.3),
                sort_by=df_homer_total[key].mean(axis=1)
            )

            fig = imshow(
                df_homer_total[key],
                x=x,
                figsize=(3, 7),
                vmin=5, vmax=99,  percentile=True,
                line_kwargs=dict(color='k', label='All'),
                fill_kwargs=dict(color='k', alpha=0.3),
                sort_by=np.argmax(df_homer_total[key], axis=1)
            )



            fig = imshow(
                df_homer_total[key],
                x=x,
                figsize=(3, 7),
                vmin=5, vmax=99,  percentile=True,
                line_kwargs=dict(color='k', label='All'),
                fill_kwargs=dict(color='k', alpha=0.3),
                sort_by=df_homer_total[key].mean(axis=1)
            )

            print("AHora viene: ", key)

            plt.show()
            


    print(normalized_subtracted,df_homer_total)

    








